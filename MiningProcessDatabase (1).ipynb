{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af146307",
   "metadata": {},
   "source": [
    "**Mining Process Flotation Plant Database**\n",
    "\n",
    "The main goal is to use this data to predict how much impurity is in the ore concentrate. As this impurity is measured every hour, if we can predict how much silica (impurity) is in the ore concentrate, we can help the engineers, giving them early information to take actions (empowering!). Hence, they will be able to take corrective actions in advance (reduce impurity, if it is the case) and also help the environment (reducing the amount of ore that goes to tailings as you reduce silica in the ore concentrate)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84b1bde",
   "metadata": {},
   "source": [
    "More Information on the dataset: \n",
    "\n",
    "The first column shows time and date range (from march of 2017 until september of 2017). Some columns were sampled every 20 second. Others were sampled on a hourly base.\n",
    "\n",
    "The second and third columns are quality measures of the iron ore pulp right before it is fed into the flotation plant. Column 4 until column 8 are the most important variables that impact in the ore quality in the end of the process. From column 9 until column 22, we can see process data (level and air flow inside the flotation columns, which also impact in ore quality. The last two columns are the final iron ore pulp quality measurement from the lab.\n",
    "Target is to predict the last column, which is the % of silica in the iron ore concentrate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178e71b7",
   "metadata": {},
   "source": [
    "**Objectives**\n",
    "\n",
    "- Is it possible to predict % Silica Concentrate every minute?\n",
    "\n",
    "- How many steps (hours) ahead can we predict % Silica in Concentrate? This would help engineers to act in predictive and optimized way, mitigatin the % of iron that could have gone to tailings.\n",
    "\n",
    "- Is it possible to predict % Silica in Concentrate whitout using % Iron Concentrate column (as they are highly correlated)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54af0c02",
   "metadata": {},
   "source": [
    "Source of data: **Kaggle**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f361a81c",
   "metadata": {},
   "source": [
    "**Project plan**\n",
    "\n",
    "1. Data Exploration and Preprocessing \n",
    "     - Python: clustering and anomaly detection \n",
    "    \n",
    "2. Correlation Analysis\n",
    "\n",
    "3. Normalization\n",
    "\n",
    "4. Variable \n",
    "    - Linear Regression\n",
    "    - Random Forest\n",
    "    \n",
    "5. Partition of the data \n",
    "\n",
    "6. Evaluation metrics\n",
    "\n",
    "7. Naive Benchmark \n",
    "\n",
    "8. Machine Learning \n",
    "    -selected methods: ,,.......\n",
    "        \n",
    "9. Sensitivity Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a125972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdd6d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\marumom\\Desktop\\DATA ANALYSIS Projects 2023\\MiningProcess_Flotation_Plant_Database.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19c3c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns\n",
    "\n",
    "#for this study we can ignore the date, focus will be on the other columns but it's not necessary to delete the date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0748ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing values\n",
    "data.isna().sum()\n",
    "#no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd5a7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()\n",
    "#later change the dtype to date and integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd9ea0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da749f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sub= data[['% Iron Feed', '% Silica Feed', 'Starch Flow', 'Amina Flow',\n",
    "       'Ore Pulp Flow', 'Ore Pulp pH', 'Ore Pulp Density',\n",
    "       'Flotation Column 01 Air Flow', 'Flotation Column 02 Air Flow',\n",
    "       'Flotation Column 03 Air Flow', 'Flotation Column 04 Air Flow',\n",
    "       'Flotation Column 05 Air Flow', 'Flotation Column 06 Air Flow',\n",
    "       'Flotation Column 07 Air Flow', 'Flotation Column 01 Level',\n",
    "       'Flotation Column 02 Level', 'Flotation Column 03 Level',\n",
    "       'Flotation Column 04 Level', 'Flotation Column 05 Level',\n",
    "       'Flotation Column 06 Level', 'Flotation Column 07 Level',\n",
    "       '% Iron Concentrate', '% Silica Concentrate']]\n",
    "data_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a164b695",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sub = data_sub.replace(regex={',' : '.'}).astype(float)\n",
    "\n",
    "#replace , with .\n",
    "#data_sub[['% Iron Feed', '% Silica Feed', 'Starch Flow','Ore Pulp Density', '% Iron Concentrate', '% Silica Concentrate']] = data_sub[['% Iron Feed', '% Silica Feed', 'Starch Flow','Ore Pulp Density', '% Iron Concentrate', '% Silica Concentrate']].replace(regex={',' : '.'}).astype(float)\n",
    "data_sub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08714f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the shape of the dataframe\n",
    "\n",
    "data_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4988b5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#boxplots to look at the data for any outliers etc\n",
    "#define a function called plot_boxplot\n",
    "#df is the respective dataframe \n",
    "#var is the feature/variable\n",
    "\n",
    "def plot_boxplot(df, var):\n",
    "    df.boxplot(column =['% Iron Feed', '% Silica Feed', 'Starch Flow', 'Amina Flow',\n",
    "       'Ore Pulp Flow', 'Ore Pulp pH', 'Ore Pulp Density',\n",
    "       'Flotation Column 01 Air Flow', 'Flotation Column 02 Air Flow',\n",
    "       'Flotation Column 03 Air Flow', 'Flotation Column 04 Air Flow',\n",
    "       'Flotation Column 05 Air Flow', 'Flotation Column 06 Air Flow',\n",
    "       'Flotation Column 07 Air Flow', 'Flotation Column 01 Level',\n",
    "       'Flotation Column 02 Level', 'Flotation Column 03 Level',\n",
    "       'Flotation Column 04 Level', 'Flotation Column 05 Level',\n",
    "       'Flotation Column 06 Level', 'Flotation Column 07 Level',\n",
    "       '% Iron Concentrate', '% Silica Concentrate'])\n",
    "    plt.grid(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675096be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_boxplot(data_sub, [['% Iron Feed', '% Silica Feed', 'Starch Flow', 'Amina Flow',\n",
    "       'Ore Pulp Flow', 'Ore Pulp pH', 'Ore Pulp Density',\n",
    "       'Flotation Column 01 Air Flow', 'Flotation Column 02 Air Flow',\n",
    "       'Flotation Column 03 Air Flow', 'Flotation Column 04 Air Flow',\n",
    "       'Flotation Column 05 Air Flow', 'Flotation Column 06 Air Flow',\n",
    "       'Flotation Column 07 Air Flow', 'Flotation Column 01 Level',\n",
    "       'Flotation Column 02 Level', 'Flotation Column 03 Level',\n",
    "       'Flotation Column 04 Level', 'Flotation Column 05 Level',\n",
    "       'Flotation Column 06 Level', 'Flotation Column 07 Level',\n",
    "       '% Iron Concentrate', '% Silica Concentrate']] )\n",
    "#results are not readable so will create subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720fcbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sub.plot( kind = 'box', subplots=True, sharey=False, layout=(5,5), figsize=(10,6))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#improved view\n",
    "#might explore better views at a later stage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce95a2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove outliers using 2 step approach\n",
    "#IQR\n",
    "\n",
    "def outliers(df, var):\n",
    "    Q1 = df[var].quantile(0.25)\n",
    "    Q3= df[var].quantile(0.75)\n",
    "    IQR = Q3 - Q1 \n",
    "    \n",
    "    lower = Q1 - 1.5*IQR\n",
    "    upper = Q3 + 1.5*IQR\n",
    "    \n",
    "    list = data_sub.index[(df[var] < lower) | (df[var] > upper)]\n",
    "    \n",
    "    return list \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec8e283",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an empty list to store the output indices from multiple columns \n",
    "\n",
    "index_list=[]\n",
    "\n",
    "#extract outliers for all columns using for loop\n",
    "\n",
    "for variable in ['% Iron Feed', '% Silica Feed', 'Starch Flow', 'Amina Flow',\n",
    "       'Ore Pulp Flow', 'Ore Pulp pH', 'Ore Pulp Density',\n",
    "       'Flotation Column 01 Air Flow', 'Flotation Column 02 Air Flow',\n",
    "       'Flotation Column 03 Air Flow', 'Flotation Column 04 Air Flow',\n",
    "       'Flotation Column 05 Air Flow', 'Flotation Column 06 Air Flow',\n",
    "       'Flotation Column 07 Air Flow', 'Flotation Column 01 Level',\n",
    "       'Flotation Column 02 Level', 'Flotation Column 03 Level',\n",
    "       'Flotation Column 04 Level', 'Flotation Column 05 Level',\n",
    "       'Flotation Column 06 Level', 'Flotation Column 07 Level',\n",
    "       '% Iron Concentrate', '% Silica Concentrate']:\n",
    "    index_list.extend(outliers(data_sub, variable))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ab09ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e583e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function called remove which will result in a clean df \n",
    "\n",
    "def remove(df, list):\n",
    "    list = sorted(set(list))\n",
    "    df = df.drop(list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84071d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned = remove(data_sub, index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d19688",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164dc60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot boxplot again to check if there still are any outliers\n",
    "\n",
    "data_cleaned.plot( kind = 'box', subplots=True, sharey=False, layout=(5,5), figsize=(10,6))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03b464f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogram to see data \n",
    "data_cleaned.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1189e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for nan values \n",
    "data_cleaned.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f61b740",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset index\n",
    "\n",
    "data_cleaned.reset_index()\n",
    "\n",
    "#drop the index column\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551b25d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the distribution of silica concentrate\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "ax = sns.countplot(x='% Silica Concentrate', data=data_cleaned )\n",
    "\n",
    "#return to fix the axes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7660166e",
   "metadata": {},
   "source": [
    "**Correlation Analysis**\n",
    "\n",
    "To examine if explanatory variables share the same linear relationship with the outcome variable in order to detect duplications of variables in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551982e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation heat map\n",
    "\n",
    "plt.figure(figsize=(16,16))\n",
    "sns.heatmap(data_cleaned[['% Iron Feed', '% Silica Feed', 'Starch Flow', 'Amina Flow',\n",
    "       'Ore Pulp Flow', 'Ore Pulp pH', \n",
    "       'Flotation Column 01 Air Flow', 'Flotation Column 02 Air Flow',\n",
    "       'Flotation Column 03 Air Flow', 'Flotation Column 04 Air Flow',\n",
    "       'Flotation Column 05 Air Flow', 'Flotation Column 06 Air Flow',\n",
    "       'Flotation Column 07 Air Flow', 'Flotation Column 01 Level',\n",
    "       'Flotation Column 02 Level', 'Flotation Column 03 Level',\n",
    "       'Flotation Column 04 Level', 'Flotation Column 05 Level',\n",
    "       'Flotation Column 06 Level', 'Flotation Column 07 Level',\n",
    "       '% Iron Concentrate','% Silica Concentrate' ]].corr(), annot = True, fmt =\".2f\")\n",
    "plt.show()\n",
    "\n",
    "#we get the pearson correlatin coefficient from the heat map -r \n",
    "#a browse of the r coefficient shows us which variables are highly correlated and those that are not correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59be076d",
   "metadata": {},
   "source": [
    "**Normalization**\n",
    "\n",
    "The variables are all numerical so no need to vectorize but they were stored on a different scale so each variable was normalized independently in order to put them on the same scale. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5dc0fb",
   "metadata": {},
   "source": [
    "Going forth, I did feature selection to reduce the number of input variables when developing a predictive model.\n",
    "I based myself on the pearson correlation coeefficients that showed the correlations between variables. \n",
    "For now, I will set aside the 'Flotation Column 01 Air Flow', 'Flotation Column 02 Air Flow',\n",
    "       'Flotation Column 03 Air Flow', 'Flotation Column 04 Air Flow',\n",
    "       'Flotation Column 05 Air Flow', 'Flotation Column 06 Air Flow',\n",
    "       'Flotation Column 07 Air Flow', 'Flotation Column 01 Level',\n",
    "       'Flotation Column 02 Level', 'Flotation Column 03 Level',\n",
    "       'Flotation Column 04 Level', 'Flotation Column 05 Level',\n",
    "       'Flotation Column 06 Level', 'Flotation Column 07 Level' independent variables and explore the remaining variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d060a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e31b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the zscores and drop zcores into new dataframe\n",
    "data_norm = zscore(data_cleaned[['% Iron Feed', '% Silica Feed', 'Starch Flow', 'Amina Flow',\n",
    "       'Ore Pulp Flow', 'Ore Pulp pH', 'Ore Pulp Density',\n",
    "              '% Iron Concentrate','% Silica Concentrate' ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b3013f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde077f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize the trends of the remaining variables with the target variable % Silica Concentrate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11ec690",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter_matrix(data_norm[['% Iron Feed', '% Silica Feed', 'Starch Flow', 'Amina Flow', 'Ore Pulp Flow', 'Ore Pulp pH',\n",
    "       'Ore Pulp Density', '% Iron Concentrate', '% Silica Concentrate']])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf212cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#take a closer look at %iron feed and %silica feed as well as %iron concentrate and %silica conc.\n",
    "\n",
    "px.scatter(x=data_norm['% Iron Feed'], y =data_norm['% Silica Feed'])\n",
    "\n",
    "#indicates a negative correlation, good spread of data points\n",
    "#could indicate possible chemical reactions taking place iron ----> silica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad90436f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "px.scatter(x=data_norm['% Iron Concentrate'], y =data_norm['% Silica Concentrate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dda7d47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "px.scatter(x=data_norm['% Iron Feed'], y =data_norm['% Iron Concentrate'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7363531",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "px.scatter(x=data_norm['% Silica Feed'], y =data_norm['% Silica Concentrate'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769eec84",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(x=data_norm['% Iron Feed'], y =data_norm['% Silica Concentrate'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd66a2c",
   "metadata": {},
   "source": [
    "**Training and testing models**\n",
    "\n",
    "I will partition the Data into two parts for training and testing purpose: 70% of the entire dataset for training the selected models using 10-fold cross validation method and 30% for testing purpose. \n",
    "\n",
    "The respective training and validation dataset were randomly sampled to circumvent sampling bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba2aeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the required libraries\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8058e3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data set into training and test dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.array(data_cleaned[['% Iron Feed', '% Silica Feed', 'Starch Flow', 'Amina Flow',\n",
    "                  'Ore Pulp Flow', 'Ore Pulp pH', 'Ore Pulp Density','% Iron Concentrate']])\n",
    "\n",
    "y = np.array(data_cleaned[['% Silica Concentrate']])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa955575",
   "metadata": {},
   "outputs": [],
   "source": [
    "#multiple linear regression \n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0aa03b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(lr, X, y, cv=10)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16927c7a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#random forest\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7dbbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(rf, X, y, cv=10)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d6d6ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c6cc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import kfold library\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits = 10 )\n",
    "kf.get_n_splits(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade07e2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
